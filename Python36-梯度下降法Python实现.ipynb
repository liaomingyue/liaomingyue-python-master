{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入需要的模块\n",
    "import numpy as np\n",
    "from numpy import genfromtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1,  1.5,  2.5],\n",
       "       [ 1.3,  1.9,  3.2],\n",
       "       [ 1.5,  2.3,  3.9],\n",
       "       [ 1.7,  2.7,  4.6],\n",
       "       [ 1.9,  3.1,  5.3],\n",
       "       [ 2.1,  3.5,  6. ],\n",
       "       [ 2.3,  3.9,  6.7],\n",
       "       [ 2.5,  4.3,  7.4],\n",
       "       [ 2.7,  4.7,  8.1],\n",
       "       [ 2.9,  5.1,  8.8]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#加载数据\n",
    "dataPath=\"files\\data\\house.csv\"\n",
    "dataSet=genfromtxt(dataPath,delimiter=',')\n",
    "dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#将数据分成自变量和因变量矩阵\n",
    "def getData(dataSet):\n",
    "    m,n=np.shape(dataSet)\n",
    "    trainData=np.ones((m,n))\n",
    "    trainData[:,:-1]=dataSet[:,:-1]\n",
    "    trainLabel=dataSet[:,-1]\n",
    "    return trainData,trainLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#实现批处理梯度下降算法\n",
    "def batchGradientDescent(x, y, theta, alpha, m, maxIterations):\n",
    "    xTrains = x.transpose()\n",
    "    for i in range(0, maxIterations):\n",
    "        hypothesis = np.dot(x, theta)\n",
    "        loss = hypothesis - y\n",
    "        gradient = np.dot(xTrains, loss) / m\n",
    "        theta = theta - alpha * gradient\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.1  1.5  1. ]\n",
      " [ 1.3  1.9  1. ]\n",
      " [ 1.5  2.3  1. ]\n",
      " [ 1.7  2.7  1. ]\n",
      " [ 1.9  3.1  1. ]\n",
      " [ 2.1  3.5  1. ]\n",
      " [ 2.3  3.9  1. ]\n",
      " [ 2.5  4.3  1. ]\n",
      " [ 2.7  4.7  1. ]\n",
      " [ 2.9  5.1  1. ]] [ 2.5  3.2  3.9  4.6  5.3  6.   6.7  7.4  8.1  8.8]\n"
     ]
    }
   ],
   "source": [
    "#初始化参数\n",
    "trainData, trainLabel = getData(dataSet)\n",
    "print(trainData,trainLabel)\n",
    "m, n = np.shape(trainData)\n",
    "theta = np.ones(n)\n",
    "alpha = 0.05\n",
    "maxIteration = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.71493625,  1.39253188, -0.37522769])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = batchGradientDescent(trainData, trainLabel, theta, alpha, m, maxIteration)\n",
    "theta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#预测函数\n",
    "def predict(x, theta):\n",
    "    m, n = np.shape(x)\n",
    "    xTest = np.ones((m, n+1))\n",
    "    xTest[:, :-1] = x\n",
    "    yPre = np.dot(xTest, theta)\n",
    "    return yPre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9.49608552  10.19523475  10.89438398  11.59353321  12.29268244]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[3.1, 5.5], [3.3, 5.9], [3.5, 6.3], [3.7, 6.7], [3.9, 7.1]])\n",
    "print(predict(x, theta)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9.5  10.2  10.9  11.6  12.3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from numpy import genfromtxt\n",
    "\n",
    "def getData(dataSet):\n",
    "    m, n = np.shape(dataSet)\n",
    "    trainData = np.ones((m, n))\n",
    "    trainData[:,:-1] = dataSet[:,:-1]\n",
    "    trainLabel = dataSet[:,-1]\n",
    "    return trainData, trainLabel\n",
    "\n",
    "def batchGradientDescent(x, y, theta, alpha, m, maxIterations):\n",
    "    xTrains = x.transpose()\n",
    "    for i in range(0, maxIterations):\n",
    "        hypothesis = np.dot(x, theta)\n",
    "        loss = hypothesis - y\n",
    "        # print loss\n",
    "        gradient = np.dot(xTrains, loss) / m\n",
    "        theta = theta - alpha * gradient\n",
    "    return theta\n",
    "\n",
    "def predict(x, theta):\n",
    "    m, n = np.shape(x)\n",
    "    xTest = np.ones((m, n+1))\n",
    "    xTest[:, :-1] = x\n",
    "    yP = np.dot(xTest, theta)\n",
    "    return yP\n",
    "\n",
    "dataPath = \"files\\data\\house.csv\"\n",
    "dataSet = genfromtxt(dataPath, delimiter=',')\n",
    "trainData, trainLabel = getData(dataSet)\n",
    "m, n = np.shape(trainData)\n",
    "theta = np.ones(n)\n",
    "alpha = 0.1\n",
    "maxIteration = 5000\n",
    "theta = batchGradientDescent(trainData, trainLabel, theta, alpha, m, maxIteration)\n",
    "x = np.array([[3.1, 5.5], [3.3, 5.9], [3.5, 6.3], [3.7, 6.7], [3.9, 7.1]])\n",
    "print(predict(x, theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
